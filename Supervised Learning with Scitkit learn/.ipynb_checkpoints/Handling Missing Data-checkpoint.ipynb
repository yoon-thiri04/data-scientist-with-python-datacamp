{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80f7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                  0\n",
      "valence                     0\n",
      "instrumentalness            0\n",
      "acousticness                0\n",
      "loudness                    0\n",
      "danceability                0\n",
      "feelings                    0\n",
      "sadness                     0\n",
      "like/girls                  0\n",
      "family/spiritual            0\n",
      "light/visual perceptions    0\n",
      "movement/places             0\n",
      "energy                      0\n",
      "music                       0\n",
      "communication               0\n",
      "romantic                    0\n",
      "family/gospel               0\n",
      "shake the audience          0\n",
      "night/time                  0\n",
      "world/life                  0\n",
      "violence                    0\n",
      "dating                      0\n",
      "len                         0\n",
      "genre                       0\n",
      "release_date                0\n",
      "obscene                     0\n",
      "age                         0\n",
      "dtype: int64\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read the data \n",
    "import pandas as pd\n",
    "\n",
    "music_df=pd.read_csv('music.csv')\n",
    "\n",
    "# missing values\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "diabetes_df=pd.read_csv('diabetes.csv')\n",
    "print(diabetes_df.isna().sum().sort_values())\n",
    "\n",
    "### The outputs indicate that there's no missing data for each of two df \n",
    "### IF it does, sort in ascending with count of missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023f105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping missing data \n",
    "music_df=music_df.dropna(subset=['genre','loudness','instrumentalness','energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A better option than droping columns with missing values ==> Imputation\n",
    "-- Imputation fills in the missing values with some number. \n",
    "-- For instance, we can fill in the mean value along each column. (mean/median/most_frequent)\n",
    "-- We must split data before imputation to avoid Data Leakage.\n",
    "\n",
    "The imputed value won't be exactly right in most cases, but it usually leads to more accurate models than \n",
    "you would get from dropping the column entirely.\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "# Use melb_data and use information such as the number of rooms and land size to predict home price.\n",
    "melb_df=pd.read_csv('melb_data.csv')\n",
    "\n",
    "# missing values\n",
    "print(melb_df.isna().sum().sort_values())\n",
    "\n",
    "X= melb_df.drop(\"Price\",axis=1)\n",
    "y= melb_df['Price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.8, test_size=0.2,\n",
    "                                                 random_state=12)\n",
    "\n",
    "# List numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())  # Scale features\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the complete pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969119c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star_data set\n",
    "star_df=pd.read_csv('star_dataset.csv')\n",
    "star_df\n",
    "\n",
    "# print the missing values\n",
    "print(star_df.isna().sum().sort_values)\n",
    "\n",
    "# drop values where less than 5% are missing\n",
    "\n",
    "star_df=star_df.dropna(subset=['Distance','Luminosity','Radius'])\n",
    "\n",
    "star_dummies=pd.get_dummies(star_df,drop_first=True).astype(int)\n",
    "star_dummies.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51831b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b30db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
